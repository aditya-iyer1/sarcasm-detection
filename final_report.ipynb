{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6eb07a-6e2b-4f40-a929-c760a1f958fa",
   "metadata": {},
   "source": [
    "# News Headline Sarcasm Detection\n",
    "\n",
    "### Authors: Aditya Iyer, Minxi Lin, David Setrakyan, Zimeng Yang\n",
    "### Course: PSTAT 134\n",
    "### Date: 16 March 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343206f6-945b-4a51-b661-1ccd28f11d2c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Overview \n",
    "\n",
    "Detecting sarcasm in text is a challenging yet important task in natural language processing (NLP), particularly for improving sentiment analysis and chatbot interactions. \n",
    "\n",
    "This project focuses on sarcasm detection in news headlines using machine learning techniques. The [dataset](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection/data), \"News Headlines Dataset for Sarcasm Detection\" by Risabh Mishra, sourced from Kaggle, contains headlines from **The Onion** (sarcastic) and **HuffPost** (non-sarcastic), providing a balanced corpus of formal news text. \n",
    "\n",
    "Our objective is to develop an NLP model capable of distinguishing sarcastic headlines from non-sarcastic ones by leveraging **exploratory data analysis, feature engineering, and various classification models**. Through tokenization, stopword removal, and word embeddings, we extract meaningful linguistic patterns that differentiate sarcasm from literal statements. \n",
    "\n",
    "Our final model, a bi-directional LSTM using pre-trained GloVe embeddings, effectively detects sarcasm with high accuracy. The results of our study offer insights into how sarcasm manifests in news language and demonstrate the effectiveness of machine learning models in identifying nuanced expressions of irony."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d9390-c4d5-4c09-8dee-7585fa2e442c",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Loading and Cleaning the Dataset\n",
    "\n",
    "#### Packages Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8de01ea-31d2-44ef-ad1f-86738bd07522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import string\n",
    "import missingno as msno\n",
    "from collections import Counter\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a793e6-a323-460d-86ab-1e6ed5f48165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_data(file):\n",
    "    for l in open(file, 'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "data = list(parse_data('data/Sarcasm_Headlines_Dataset_v2.json'))\n",
    "data = pd.DataFrame(data)\n",
    "df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55274179-d516-41b3-ab10-160ea11bacdb",
   "metadata": {},
   "source": [
    "#### Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5ee055-f5b2-4b58-b4d3-dedfc6c113cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   is_sarcastic  28619 non-null  int64 \n",
      " 1   headline      28619 non-null  object\n",
      " 2   article_link  28619 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 670.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611e536-7b19-4b66-9004-8ae1ac1e7898",
   "metadata": {},
   "source": [
    "There are a total of 28619 rows and 3 columns in the dataset. is_sarcastic is a binary variable consisting of 0 and 1. headline and article_link are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c134cf71-85d9-480c-b8dd-46b6fee6073b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1817b-4866-45f5-8110-025ba4f3f30a",
   "metadata": {},
   "source": [
    "The dataset is loaded from a json file using `parse_data()`, and then stored in a pandas dataframe. The dataset has 3 columns:\n",
    "\n",
    "- `is_sarcastic`: Binary target variable (1 for sarcastic, 0 for non-sarcastic)\n",
    "- `headline`: The actual news headline text\n",
    "- `article_link`: The source link for the article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cf318-125c-4825-8488-ca80cd969126",
   "metadata": {},
   "source": [
    "### Missing and Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43609ae-d7e2-48b4-ad3a-35bbd4428b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       is_sarcastic                                           headline  \\\n",
      "646               0                        hillary clinton vs. herself   \n",
      "14897             1  nation not sure how many ex-trump staffers it ...   \n",
      "18572             0                        hillary clinton vs. herself   \n",
      "25743             1  nation not sure how many ex-trump staffers it ...   \n",
      "\n",
      "                                            article_link  \n",
      "646    https://www.huffingtonpost.comhttp://nymag.com...  \n",
      "14897  https://politics.theonion.com/nation-not-sure-...  \n",
      "18572  https://www.huffingtonpost.comhttp://nymag.com...  \n",
      "25743  https://politics.theonion.com/nation-not-sure-...  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(data)\n",
    "\n",
    "print(df[df.duplicated(keep = False)])\n",
    "df = df[df.duplicated(keep='first') == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2352f-8538-4226-a2a6-df0486412e0a",
   "metadata": {},
   "source": [
    "The dataset had no missing data, as well as two duplicated rows, so we removed them from the dataset as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c78e81-2901-45ca-aa6f-9f12f65ba01f",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "#### Sarcastic vs Non-Sarcastic Headline Distributions\n",
    "\n",
    "![Sarcastic vs Non-Sarcastic Headline Distributions](/Users/aditya/Documents/ucsb/pstat-134/sarcasm-detection/images/headline_distr.png)\n",
    "\n",
    "The two classes are almost balanced, with the number of non-sarcastic headlines being slightly higher. The \"Not sarcastic\" class has approximately 15,000 values and \"sarcastic\" class has approximately 13,500 values.\n",
    "\n",
    "#### Most Commonly Occurring Bigrams for both Headline Types\n",
    "\n",
    "![bigrams](/Users/aditya/Documents/ucsb/pstat-134/sarcasm-detection/images/common_words.png)\n",
    "\n",
    "\n",
    "The five most commonly-occurring bigrams for sarcastic headlines are *area man*, *white house*, *study finds*, *introduces new*, and *unveils new*. The five most commonly-occurring bigrams for non-sarcastic headlines are *donald trump*, *hilary clinton*, *donald trumps*, *new york*, and *white house*. The frequencies of area man and donald trump significantly outnumber the other bigrams separately in sarcastic and not sarcastic classes. It seems that the full names of celebrities, particularly political figures in many of these cases, are more likely to occur in non-sarcastic headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09e61e-5399-4595-891c-336f44a3e1bc",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis\n",
    "\n",
    "#### Most Commonly Occurring words by sentiment\n",
    "\n",
    "![word_cloud_image](/Users/aditya/Documents/ucsb/pstat-134/sarcasm-detection/images/word_cloud_full.png)\n",
    "\n",
    "Words with positive sentiments are more common than these with negative sentiments. The most commonly-occurring words with 'positive' sentiment are 'like', 'good', and 'best', and the most common words with negative sentiment are 'death', 'dead', 'war' and 'stop'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da13ff4-ee9e-4426-8382-987cd3ba2a31",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Feature Engineering\n",
    "\n",
    "Before training our sarcasm detection models, we **preprocessed the dataset** to ensure it was in a structured numerical format suitable for machine learning and deep learning models.\n",
    "\n",
    "1. **Text Cleaning & Tokenization**:  \n",
    "   - We removed punctuation and special characters.  \n",
    "   - Headlines were converted to lowercase and tokenized into individual words.  \n",
    "   - Stopwords (e.g., \"the\", \"is\", \"and\") were removed to improve efficiency.\n",
    "\n",
    "2. **Numerical Representation of Text**:  \n",
    "   - We created a **vocabulary dictionary**, assigning a unique index to each word.  \n",
    "   - Headlines were then **converted into sequences of word indices**.  \n",
    "   - Headlines were **padded to a fixed length (25 words)** to standardize input size.\n",
    "\n",
    "3. **Using Pre-Trained Word Embeddings (GloVe)**:  \n",
    "   - Instead of training embeddings from scratch, we used **pre-trained GloVe embeddings (100D)**.  \n",
    "   - We mapped our vocabulary to **GloVe vectors**, ensuring our model leveraged high-quality word representations.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a124931-aa35-48e6-92e9-ca1f05ffc833",
   "metadata": {},
   "source": [
    "#### Re-reading in the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472eb3a-83bf-48b5-8dbb-18291b2b4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data.columns = ['Sarcastic', 'Headline', 'Link']\n",
    "\n",
    "# 1. Clean text, remove punctuation, and stopwords\n",
    "stop_words_removed = []\n",
    "for i in data['Headline']:\n",
    "    i = re.sub(r\"[^a-zA-Z\\s]\", \"\", i)  # Remove special characters\n",
    "    main_words = ' '.join([j for j in i.split() if j.lower() not in ENGLISH_STOP_WORDS])\n",
    "    stop_words_removed.append(main_words)\n",
    "\n",
    "# 2. Tokenization\n",
    "tokenized_corpus = [word_tokenize(i) for i in stop_words_removed]\n",
    "vocab = set([word for sentence in tokenized_corpus for word in sentence])\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# 3. Convert words to numerical indices\n",
    "tokenized_corpus_num = [[word_to_idx[word] for word in headline] for headline in tokenized_corpus]\n",
    "\n",
    "# 4. Padding sequences to 25 words\n",
    "tensor_corpus = [torch.tensor(seq, dtype=torch.long) for seq in tokenized_corpus_num]\n",
    "padded_sequences = pad_sequence(tensor_corpus, batch_first=True, padding_value=len(vocab))\n",
    "padded_sequences = padded_sequences[:, :25]  # Truncate to max_length = 25\n",
    "\n",
    "# 5. Prepare labels\n",
    "sarcasm = torch.tensor(data['Sarcastic'].values, dtype=torch.long)\n",
    "\n",
    "# 6. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, sarcasm, test_size=0.2, stratify=sarcasm, shuffle=True)\n",
    "\n",
    "# 7. Load pre-trained GloVe embeddings\n",
    "embedding_dim = 100\n",
    "embeddings_index = {}\n",
    "with open('glove.twitter.27B.100d.txt', encoding=\"utf-8\") as GloVe:\n",
    "    for entry in GloVe:\n",
    "        values = entry.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coeffs\n",
    "\n",
    "# 8. Create embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_to_idx) + 1, embedding_dim))\n",
    "for word, i in word_to_idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ce448-d390-42e8-9411-70139c44b479",
   "metadata": {},
   "source": [
    "### Model Selection Performance Comparison\n",
    "\n",
    "We experimented with multiple models before selecting the **GloVe LSTM** as our final model. Below is a comparison of each model's performance, along with key observations.\n",
    "\n",
    "| Model | Accuracy | Explanation |\n",
    "|-------|----------|----------------------------------------------|\n",
    "| **CBOW Embeddings Model** | 51.2% | Performed poorly due to **lack of continuous data**headline texts are independent, unlike books or long documents where CBOW typically excels. |\n",
    "| **Skip-Gram Word2Vec** | 56.8% | Outperformed CBOW but still struggled due to **limited training data**. Performed worse than Logistic Regression. |\n",
    "| **Logistic Regression (TF-IDF + Features)** | 79.9% | Used **headline length, punctuation features (exclamation/question marks), and TF-IDF unigram features**, but additional predictors had **negligible impact**. Hyperparameter tuning showed the default model was already optimal. |\n",
    "| **GloVe LSTM Model (Final)** | **98.6%** | Used **pre-trained Twitter GloVe embeddings** with an **LSTM classifier**, significantly outperforming other models due to its ability to capture **contextual relationships in sarcasm**. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfd21c-2efc-4249-9254-42fedf65adcd",
   "metadata": {},
   "source": [
    "### Final Model: GloVe LSTM for Sarcasm Detection\n",
    "\n",
    "## Final Model: GloVe LSTM for Sarcasm Detection\n",
    "\n",
    "Our final model is a **bi-directional LSTM** using **pre-trained GloVe embeddings**, which achieved the highest accuracy (98.6%) in sarcasm classification.  \n",
    "\n",
    "### Why We Chose This Model:\n",
    "- **Captures contextual meaning** in text better than traditional models.\n",
    "- **Uses pre-trained word embeddings (GloVe)** instead of training from scratch.\n",
    "- **Bi-directional LSTM** tracks long-term dependencies, making it ideal for sarcastic sentence structures.\n",
    "\n",
    "### Model Architecture:\n",
    "1. **Embedding Layer**: Uses pre-trained GloVe word embeddings.\n",
    "2. **Bi-Directional LSTM**: Processes text in both forward and backward directions.\n",
    "3. **Fully Connected Layer**: Produces a probability output for sarcasm detection.\n",
    "4. **Sigmoid Activation**: Converts the model's output into a binary classification (sarcastic vs. non-sarcastic).\n",
    "\n",
    "\n",
    "The implementation can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dd700b-aacc-4005-8060-83d4ddc8b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SarcasmLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim=64, dropout=0.2, rdropout=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load pre-trained GloVe embeddings (frozen)\n",
    "        self.embedding_layer = Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32), \n",
    "            freeze=True, \n",
    "            padding_idx=len(vocab)\n",
    "        )\n",
    "\n",
    "        # Bi-directional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=100, \n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True, \n",
    "            dropout=rdropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "        # Sigmoid activation function for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Take the last hidden state\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f14464-cf86-449d-b331-00609daf7515",
   "metadata": {},
   "source": [
    "### Model Training & Optimization\n",
    "\n",
    "We trained our **GloVe LSTM model** using **Binary Cross-Entropy Loss (BCELoss)** for binary classification and optimized it with the **Adam optimizer (learning rate = 0.001)**. The dataset was **converted into PyTorch tensors** and split into **80% training and 20% testing** sets. Training was conducted over **30 epochs** using **mini-batches (batch size = 32)** to improve stability and efficiency. Accuracy was tracked at each epoch to monitor performance. After optimizing the model's weights through **backpropagation**, we saved the final trained model for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535a1c0-b1dd-4555-9601-ba42ae8dc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for PyTorch\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Prepare data loaders\n",
    "train_dataset = SarcasmDataset(X_train, y_train)\n",
    "test_dataset = SarcasmDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cpu\")\n",
    "model2 = SarcasmLSTM(embedding_matrix=embedding_matrix).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track performance\n",
    "        total_loss += loss.item()\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # Compute loss and accuracy\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model2.state_dict(), \"sarcasm_lstm_GloVe2.pth\")\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf2b92-1c10-4e43-9794-384487d388bc",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341cce9-83b6-4ccc-9c2b-6e63cd77f517",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "After **30 epochs of training**, our model achieved **98.6% accuracy**, significantly outperforming all other models tested.\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Final Accuracy** | 98.6% |\n",
    "| **Final Testing Loss** | 0.22 |\n",
    "| **Best Alternative Model (Logistic Regression)** | 79.9% |\n",
    "\n",
    "### Key Takeaways:\n",
    "- **The LSTM model successfully captured long-term dependencies** in sarcastic text.\n",
    "- **Using pre-trained GloVe embeddings significantly improved performance** compared to CBOW/Skip-Gram.\n",
    "- **Unlike logistic regression**, which relied on manual feature engineering, LSTMs learn **contextual meaning from raw text**.\n",
    "\n",
    "The below visualization shows how the GloVe model's test loss changed over time, with the x-axis representing epochs and the y-axis representing test loss, how the model is performing on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6348781-6c47-4d4e-bb98-776721400ebb",
   "metadata": {},
   "source": [
    "\n",
    "![Test Loss Graph for GloVe LSTM Model](/Users/aditya/Documents/ucsb/pstat-134/sarcasm-detection/images/test_loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce357a9-68e5-4e31-97b1-39ba5cb848a6",
   "metadata": {},
   "source": [
    "The model starts with a higher test loss, around ~0.45, and reaches a low point around epoch 15. After that, from epochs 15 to 30, the test loss oscillates, but we tested this for overfitting - the model here is simply adjusting weights and fine-tuning them, rather than overfitting as the test loss doesn't seem to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f4e51-0c37-4cb0-94c7-7cb2961f9cc4",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n",
    "Our final model selection was driven by accuracy and ability to capture contextual sarcasm. \n",
    "While traditional models like **Logistic Regression** performed reasonably well (79.9%), neural network approaches showed the most promise. \n",
    "Both **CBOW (51.2%)** and **Skip-Gram (56.8%)** struggled due to the datasets independent headline structure. \n",
    "By leveraging **pre-trained GloVe embeddings**, our **GloVe LSTM model reached 98.6% accuracy**, demonstrating its superior capability in sarcasm detection.\n",
    "\n",
    "\n",
    "We modified the training of the model by testing it on both V1 and V2 of the dataset (Both contain their own unique data). V2 was the standard used for this project (With more recent headlines), and V1 was the original. When trained on V1 **and** V2, the model then had a testing accuracy of 95.3% on the overall training set compared to the 98.6% accuracy of the model trained only on V2. This could represent some bias in the way it trained, but we expect this. Since the time range for both datasets are different, key differentiators in the V2 dataset (non-sarcastic articles talking about Trump, Hillary, etc) might not have applied as much to V1 content. However, the 95.3% accuracy is still extremely high.\n",
    "\n",
    "Additionally, the accuracy and error rates were similar for both sarcastic and non sarcastic headlines, showing that the model didn't over or under-report a certain type of headline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580adee8-ccae-49c2-adb5-3bbf1baacc48",
   "metadata": {},
   "source": [
    "## Conclusion & Future Work\n",
    "\n",
    "Our study demonstrates that deep learning models leveraging GloVe embeddings are highly effective for sarcasm detection. Our Bi-directional LSTM model achieved 98.6% accuracy, outperforming traditional machine learning approaches. Despite this success, sarcasm detection remains inherently challenging due to its contextual nature. Future work could incorporate Transformer-based models like BERT, which excel in contextual understanding, and multimodal sarcasm detection by combining textual and visual cues from memes or GIFs. Expanding the dataset to include social media sarcasm (e.g., Twitter, Reddit) would further enhance real-world applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbadd369-b5b0-4d8c-9159-8e2278864c74",
   "metadata": {},
   "source": [
    "## References\n",
    "- Mishra, R. (2019). *News Headlines Dataset for Sarcasm Detection*. [Kaggle Dataset](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection/data)\n",
    "- Pennington, J., Socher, R., & Manning, C. (2014). *GloVe: Global Vectors for Word Representation*. [Paper](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "- Hochreiter, S., & Schmidhuber, J. (1997). *Long Short-Term Memory*. Neural Computation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
